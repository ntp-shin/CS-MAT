Start

Training options:
{
  "num_gpus": 2,
  "image_snapshot_ticks": 10,
  "network_snapshot_ticks": 10,
  "metrics": [
    "fid2993_full"
  ],
  "random_seed": 0,
  "training_set_kwargs": {
    "class_name": "datasets.dataset_512.ImageFolderMaskDataset",
    "path": "/media/nnthao/MAT/Data/CelebA-HQ/CelebA-HQ-img",
    "use_labels": false,
    "max_size": 27007,
    "xflip": true,
    "resolution": 512
  },
  "val_set_kwargs": {
    "class_name": "datasets.dataset_512.ImageFolderMaskDataset",
    "path": "/media/nnthao/MAT/Data/CelebA-HQ/CelebA-HQ-val_img",
    "use_labels": false,
    "max_size": 2993,
    "xflip": false,
    "resolution": 512
  },
  "data_loader_kwargs": {
    "pin_memory": true,
    "num_workers": 3,
    "prefetch_factor": 2
  },
  "G_kwargs": {
    "class_name": "networks.mat.Generator",
    "z_dim": 512,
    "w_dim": 512,
    "mapping_kwargs": {
      "num_layers": 8
    },
    "synthesis_kwargs": {
      "channel_base": 32768,
      "channel_max": 512
    }
  },
  "D_kwargs": {
    "class_name": "networks.mat.Discriminator",
    "channel_base": 32768,
    "channel_max": 512,
    "mbstd_group_size": 8
  },
  "G_opt_kwargs": {
    "class_name": "torch.optim.Adam",
    "lr": 0.001,
    "betas": [
      0,
      0.99
    ],
    "eps": 1e-08
  },
  "D_opt_kwargs": {
    "class_name": "torch.optim.Adam",
    "lr": 0.001,
    "betas": [
      0,
      0.99
    ],
    "eps": 1e-08
  },
  "loss_kwargs": {
    "class_name": "losses.loss.TwoStageLoss",
    "r1_gamma": 10,
    "pcp_ratio": 0.1,
    "pl_weight": 0,
    "truncation_psi": 0.5,
    "style_mixing_prob": 0.5
  },
  "total_kimg": 480,
  "batch_size": 8,
  "batch_gpu": 4,
  "ema_kimg": 10,
  "ema_rampup": null,
  "resume_pkl": "/media/nnthao/MAT/saved_model/cswint_v4/00017-CelebA-HQ-img-mirror-celeba512-mat-lr0.001-TwoStageLoss-pr0.1-nopl-kimg600-batch8-tc0.5-sm0.5-ema10-noaug-resumecustom/network-snapshot-000120.pkl",
  "ada_kimg": 100,
  "run_dir": "/media/nnthao/MAT/saved_model/cswint_v4/00019-CelebA-HQ-img-mirror-celeba512-mat-lr0.001-TwoStageLoss-pr0.1-nopl-kimg480-batch8-tc0.5-sm0.5-ema10-noaug-resumecustom"
}

Output directory:   /media/nnthao/MAT/saved_model/cswint_v4/00019-CelebA-HQ-img-mirror-celeba512-mat-lr0.001-TwoStageLoss-pr0.1-nopl-kimg480-batch8-tc0.5-sm0.5-ema10-noaug-resumecustom
Training data:      /media/nnthao/MAT/Data/CelebA-HQ/CelebA-HQ-img
Training duration:  480 kimg
Number of GPUs:     2
Number of images:   27007
Image resolution:   512
Conditional model:  False
Dataset x-flips:    True

Validation options:
Validation data:      /media/nnthao/MAT/Data/CelebA-HQ/CelebA-HQ-val_img
Number of images:   2993
Image resolution:   512
Conditional model:  False
Dataset x-flips:    False

Creating output directory...
Launching processes...
Loading training set...

Num images:  54014
Image shape: [3, 512, 512]
Label shape: [0]

Constructing networks...
Resuming from "/media/nnthao/MAT/saved_model/cswint_v4/00017-CelebA-HQ-img-mirror-celeba512-mat-lr0.001-TwoStageLoss-pr0.1-nopl-kimg600-batch8-tc0.5-sm0.5-ema10-noaug-resumecustom/network-snapshot-000120.pkl"
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Failed!
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.
Traceback (most recent call last):
  File "train.py", line 648, in <module>
    main() # pylint: disable=no-value-for-parameter
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/click/decorators.py", line 33, in new_func
    return f(get_current_context(), *args, **kwargs)
  File "train.py", line 643, in main
    torch.multiprocessing.spawn(fn=subprocess_fn, args=(args, temp_dir), nprocs=args.num_gpus)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/media/nnthao/lntuong/FDA-v4/train.py", line 471, in subprocess_fn
    training_loop.training_loop(rank=rank, **args)
  File "/media/nnthao/lntuong/FDA-v4/training/training_loop.py", line 172, in training_loop
    img = misc.print_module_summary(G, [img_in, mask_in, z, c])
  File "/media/nnthao/lntuong/FDA-v4/torch_utils/misc.py", line 218, in print_module_summary
    outputs = module(*inputs)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/lntuong/FDA-v4/networks/mat.py", line 1120, in forward
    img = self.synthesis(images_in, masks_in, ws, noise_mode=noise_mode)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/lntuong/FDA-v4/networks/mat.py", line 1056, in forward
    out_stg1 = self.first_stage(images_in, masks_in, ws, noise_mode=noise_mode)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/lntuong/FDA-v4/networks/mat.py", line 985, in forward
    x, mask = block(x, mask)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/lntuong/FDA-v4/networks/mat.py", line 102, in forward
    x = self.conv(x)
  File "/media/nnthao/miniconda3/envs/MAT/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/lntuong/FDA-v4/networks/basic_module.py", line 96, in forward
    x = conv2d_resample.conv2d_resample(x=x, w=w, f=self.resample_filter, up=self.up, down=self.down,
  File "/media/nnthao/lntuong/FDA-v4/torch_utils/misc.py", line 101, in decorator
    return fn(*args, **kwargs)
  File "/media/nnthao/lntuong/FDA-v4/torch_utils/ops/conv2d_resample.py", line 120, in conv2d_resample
    x = upfirdn2d.upfirdn2d(x=x, f=f, padding=[px0,px1,py0,py1], flip_filter=flip_filter)
  File "/media/nnthao/lntuong/FDA-v4/torch_utils/ops/upfirdn2d.py", line 163, in upfirdn2d
    return _upfirdn2d_cuda(up=up, down=down, padding=padding, flip_filter=flip_filter, gain=gain).apply(x, f)
  File "/media/nnthao/lntuong/FDA-v4/torch_utils/ops/upfirdn2d.py", line 237, in forward
    y = _plugin.upfirdn2d(y, f, upx, upy, downx, downy, padx0, padx1, pady0, pady1, flip_filter, gain)
RuntimeError: CUDA error: no kernel image is available for execution on the device

