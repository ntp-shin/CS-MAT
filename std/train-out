Start

Training options:
{
  "num_gpus": 2,
  "image_snapshot_ticks": 50,
  "network_snapshot_ticks": 50,
  "metrics": [
    "fid2993_full"
  ],
  "random_seed": 0,
  "training_set_kwargs": {
    "class_name": "datasets.dataset_512.ImageFolderMaskDataset",
    "path": "/media/nnthao/MAT/Data/CelebA-HQ/CelebA-HQ-img",
    "use_labels": false,
    "max_size": 27007,
    "xflip": true,
    "resolution": 512
  },
  "val_set_kwargs": {
    "class_name": "datasets.dataset_512.ImageFolderMaskDataset",
    "path": "/media/nnthao/MAT/Data/CelebA-HQ/CelebA-HQ-val_img",
    "use_labels": false,
    "max_size": 2993,
    "xflip": false,
    "resolution": 512
  },
  "data_loader_kwargs": {
    "pin_memory": true,
    "num_workers": 3,
    "prefetch_factor": 2
  },
  "G_kwargs": {
    "class_name": "networks.mat.Generator",
    "z_dim": 512,
    "w_dim": 512,
    "mapping_kwargs": {
      "num_layers": 8
    },
    "synthesis_kwargs": {
      "channel_base": 32768,
      "channel_max": 512
    }
  },
  "D_kwargs": {
    "class_name": "networks.mat.Discriminator",
    "channel_base": 32768,
    "channel_max": 512,
    "mbstd_group_size": 8
  },
  "G_opt_kwargs": {
    "class_name": "torch.optim.Adam",
    "lr": 0.001,
    "betas": [
      0,
      0.99
    ],
    "eps": 1e-08
  },
  "D_opt_kwargs": {
    "class_name": "torch.optim.Adam",
    "lr": 0.001,
    "betas": [
      0,
      0.99
    ],
    "eps": 1e-08
  },
  "loss_kwargs": {
    "class_name": "losses.loss.TwoStageLoss",
    "r1_gamma": 10,
    "pcp_ratio": 0.1,
    "pl_weight": 0,
    "truncation_psi": 0.5,
    "style_mixing_prob": 0.5
  },
  "total_kimg": 25000,
  "batch_size": 16,
  "batch_gpu": 8,
  "ema_kimg": 10,
  "ema_rampup": null,
  "run_dir": "/media/nnthao/MAT/saved_model/00017-CelebA-HQ-img-mirror-celeba512-mat-lr0.001-TwoStageLoss-pr0.1-nopl-kimg25000-batch16-tc0.5-sm0.5-ema10-noaug"
}

Output directory:   /media/nnthao/MAT/saved_model/00017-CelebA-HQ-img-mirror-celeba512-mat-lr0.001-TwoStageLoss-pr0.1-nopl-kimg25000-batch16-tc0.5-sm0.5-ema10-noaug
Training data:      /media/nnthao/MAT/Data/CelebA-HQ/CelebA-HQ-img
Training duration:  25000 kimg
Number of GPUs:     2
Number of images:   27007
Image resolution:   512
Conditional model:  False
Dataset x-flips:    True

Validation options:
Validation data:      /media/nnthao/MAT/Data/CelebA-HQ/CelebA-HQ-val_img
Number of images:   2993
Image resolution:   512
Conditional model:  False
Dataset x-flips:    False

Creating output directory...
Launching processes...
Loading training set...

Num images:  54014
Image shape: [3, 512, 512]
Label shape: [0]

Constructing networks...
YOLOv5 ðŸš€ 2023-12-16 Python-3.8.18 torch-1.8.0+cu111 CUDA:0 (NVIDIA A100-SXM4-40GB, 40337MiB)
                                                     CUDA:1 (NVIDIA A100-SXM4-40GB, 40337MiB)

YOLOv5 ðŸš€ 2023-12-16 Python-3.8.18 torch-1.8.0+cu111 CUDA:0 (NVIDIA A100-SXM4-40GB, 40337MiB)
                                                     CUDA:1 (NVIDIA A100-SXM4-40GB, 40337MiB)

Fusing layers... 
Fusing layers... 
Model summary: 368 layers, 46219069 parameters, 0 gradients, 108.5 GFLOPs
Model summary: 368 layers, 46219069 parameters, 0 gradients, 108.5 GFLOPs
Setting up PyTorch plugin "bias_act_plugin"... Done.
<class 'torch.Tensor'> torch.Size([8, 1, 512, 512]) tensor(1., device='cuda:0')
<class 'torch.Tensor'> torch.Size([8, 1, 512, 512]) tensor(0.15690, device='cuda:0')
<class 'torch.Tensor'> torch.Size([8, 3, 512, 512]) tensor(0.14920, device='cuda:0')
8
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator                             Parameters  Buffers  Output shape        Datatype
---                                   ---         ---      ---                 ---     
mapping.fc0                           262656      -        [8, 512]            float32 
mapping.fc1                           262656      -        [8, 512]            float32 
mapping.fc2                           262656      -        [8, 512]            float32 
mapping.fc3                           262656      -        [8, 512]            float32 
mapping.fc4                           262656      -        [8, 512]            float32 
mapping.fc5                           262656      -        [8, 512]            float32 
mapping.fc6                           262656      -        [8, 512]            float32 
mapping.fc7                           262656      -        [8, 512]            float32 
mapping                               -           512      [8, 12, 512]        float32 
synthesis.first_stage.yolov5.model:0  46219069    60151    [1, 3, 64, 64, 21]  float32 
synthesis.first_stage.yolov5.model:1  -           -        [1, 3, 64, 64, 21]  float32 
synthesis.first_stage.yolov5.model:2  -           -        [1, 3, 64, 64, 21]  float32 
synthesis.first_stage.yolov5:0        -           -        [8, 3, 64, 64, 21]  float32 
synthesis.first_stage.yolov5:1        -           -        [8, 3, 64, 64, 21]  float32 
synthesis.first_stage.yolov5:2        -           -        [8, 3, 64, 64, 21]  float32 
synthesis.first_stage.conv_first:0    8280        16       [8, 180, 512, 512]  float32 
synthesis.first_stage.conv_first:1    -           -        [8, 180, 512, 512]  float32 
synthesis.first_stage.enc_conv.0:0    291780      16       [8, 180, 256, 256]  float32 
synthesis.first_stage.enc_conv.0:1    -           -        [8, 180, 256, 256]  float32 
synthesis.first_stage.enc_conv.1:0    291780      16       [8, 180, 128, 128]  float32 
synthesis.first_stage.enc_conv.1:1    -           -        [8, 180, 128, 128]  float32 
synthesis.first_stage.enc_conv.2:0    291780      16       [8, 180, 64, 64]    float32 
synthesis.first_stage.enc_conv.2:1    -           -        [8, 180, 64, 64]    float32 
synthesis.first_stage.tran.0:0        942660      262160   [8, 4096, 180]      float32 
synthesis.first_stage.tran.0:1        -           -        [8, 4096, 180]      float32 
synthesis.first_stage.tran.1:0        1559880     262176   [8, 1024, 180]      float32 
synthesis.first_stage.tran.1:1        -           -        [8, 1024, 180]      float32 
synthesis.first_stage.tran.2          1885320     32       [8, 256, 180]       float32 
synthesis.first_stage.ws_style        92340       -        [8, 180]            float32 
synthesis.first_stage.to_square       46336       -        [8, 256]            float32 
synthesis.first_stage.down_conv       1167120     64       [8, 180, 1, 1]      float32 
synthesis.first_stage.to_style        65160       -        [8, 360]            float32 
synthesis.first_stage.tran.3          1559880     262176   [8, 1024, 180]      float32 
synthesis.first_stage.tran.4          1234440     262176   [8, 4096, 180]      float32 
synthesis.first_stage.dec_conv.0:0    876243      64       [8, 180, 128, 128]  float32 
synthesis.first_stage.dec_conv.0:1    -           -        [8, 180, 128, 128]  float32 
synthesis.first_stage.dec_conv.1:0    876243      64       [8, 180, 256, 256]  float32 
synthesis.first_stage.dec_conv.1:1    -           -        [8, 180, 256, 256]  float32 
synthesis.first_stage.dec_conv.2:0    876243      64       [8, 180, 512, 512]  float32 
synthesis.first_stage.dec_conv.2:1    -           -        [8, 180, 512, 512]  float32 
synthesis.first_stage                 -           -        [8, 3, 512, 512]    float32 
synthesis.enc.EncConv_Block_512x512   37440       32       [8, 64, 512, 512]   float32 
synthesis.enc.EncConv_Block_256x256   221440      32       [8, 128, 256, 256]  float32 
synthesis.enc.EncConv_Block_128x128   885248      32       [8, 256, 128, 128]  float32 
synthesis.enc.EncConv_Block_64x64     3539968     32       [8, 512, 64, 64]    float32 
synthesis.enc.EncConv_Block_32x32     4719616     32       [8, 512, 32, 32]    float32 
synthesis.enc.EncConv_Block_16x16     4719616     32       [8, 512, 16, 16]    float32 
synthesis.to_square                   131328      -        [8, 256]            float32 
synthesis.to_style.conv               7079424     48       [8, 512, 2, 2]      float32 
synthesis.to_style.pool               -           -        [8, 512, 1, 1]      float32 
synthesis.to_style.fc                 525312      -        [8, 1024]           float32 
synthesis.dec.Dec_16x16:0             6295044     320      [8, 512, 16, 16]    float32 
synthesis.dec.Dec_16x16:1             -           -        [8, 512, 16, 16]    float32 
synthesis.dec.Dec_32x32:0             7081989     2112     [8, 512, 32, 32]    float32 
synthesis.dec.Dec_32x32:1             -           -        [8, 512, 32, 32]    float32 
synthesis.dec.Dec_64x64:0             7081989     8256     [8, 512, 64, 64]    float32 
synthesis.dec.Dec_64x64:1             -           -        [8, 512, 64, 64]    float32 
synthesis.dec.Dec_128x128:0           3344645     32832    [8, 256, 128, 128]  float32 
synthesis.dec.Dec_128x128:1           -           -        [8, 256, 128, 128]  float32 
synthesis.dec.Dec_256x256:0           1229957     131136   [8, 128, 256, 256]  float32 
synthesis.dec.Dec_256x256:1           -           -        [8, 128, 256, 256]  float32 
synthesis.dec.Dec_512x512:0           504389      524352   [8, 64, 512, 512]   float32 
synthesis.dec.Dec_512x512:1           -           -        [8, 64, 512, 512]   float32 
synthesis                             -           -        [8, 3, 512, 512]    float32 
---                                   ---         ---      ---                 ---     
Total                                 107783207   1808951  -                   -       


Discriminator     Parameters  Buffers  Output shape        Datatype
---               ---         ---      ---                 ---     
Dis.0.conv        320         16       [8, 64, 512, 512]   float32 
Dis.1.skip        8192        16       [8, 128, 256, 256]  float32 
Dis.1.conv0       36928       16       [8, 64, 512, 512]   float32 
Dis.1.conv1       73856       16       [8, 128, 256, 256]  float32 
Dis.1             -           -        [8, 128, 256, 256]  float32 
Dis.2.skip        32768       16       [8, 256, 128, 128]  float32 
Dis.2.conv0       147584      16       [8, 128, 256, 256]  float32 
Dis.2.conv1       295168      16       [8, 256, 128, 128]  float32 
Dis.2             -           -        [8, 256, 128, 128]  float32 
Dis.3.skip        131072      16       [8, 512, 64, 64]    float32 
Dis.3.conv0       590080      16       [8, 256, 128, 128]  float32 
Dis.3.conv1       1180160     16       [8, 512, 64, 64]    float32 
Dis.3             -           -        [8, 512, 64, 64]    float32 
Dis.4.skip        262144      16       [8, 512, 32, 32]    float32 
Dis.4.conv0       2359808     16       [8, 512, 64, 64]    float32 
Dis.4.conv1       2359808     16       [8, 512, 32, 32]    float32 
Dis.4             -           -        [8, 512, 32, 32]    float32 
Dis.5.skip        262144      16       [8, 512, 16, 16]    float32 
Dis.5.conv0       2359808     16       [8, 512, 32, 32]    float32 
Dis.5.conv1       2359808     16       [8, 512, 16, 16]    float32 
Dis.5             -           -        [8, 512, 16, 16]    float32 
Dis.6.skip        262144      16       [8, 512, 8, 8]      float32 
Dis.6.conv0       2359808     16       [8, 512, 16, 16]    float32 
Dis.6.conv1       2359808     16       [8, 512, 8, 8]      float32 
Dis.6             -           -        [8, 512, 8, 8]      float32 
Dis.7.skip        262144      16       [8, 512, 4, 4]      float32 
Dis.7.conv0       2359808     16       [8, 512, 8, 8]      float32 
Dis.7.conv1       2359808     16       [8, 512, 4, 4]      float32 
Dis.7             -           -        [8, 512, 4, 4]      float32 
Dis.8             -           -        [8, 513, 4, 4]      float32 
Dis.9             2364416     16       [8, 512, 4, 4]      float32 
fc0               4194816     -        [8, 512]            float32 
fc1               513         -        [8, 1]              float32 
Dis_stg1.0.conv   160         16       [8, 32, 512, 512]   float32 
Dis_stg1.1.skip   2048        16       [8, 64, 256, 256]   float32 
Dis_stg1.1.conv0  9248        16       [8, 32, 512, 512]   float32 
Dis_stg1.1.conv1  18496       16       [8, 64, 256, 256]   float32 
Dis_stg1.1        -           -        [8, 64, 256, 256]   float32 
Dis_stg1.2.skip   8192        16       [8, 128, 128, 128]  float32 
Dis_stg1.2.conv0  36928       16       [8, 64, 256, 256]   float32 
Dis_stg1.2.conv1  73856       16       [8, 128, 128, 128]  float32 
Dis_stg1.2        -           -        [8, 128, 128, 128]  float32 
Dis_stg1.3.skip   32768       16       [8, 256, 64, 64]    float32 
Dis_stg1.3.conv0  147584      16       [8, 128, 128, 128]  float32 
Dis_stg1.3.conv1  295168      16       [8, 256, 64, 64]    float32 
Dis_stg1.3        -           -        [8, 256, 64, 64]    float32 
Dis_stg1.4.skip   65536       16       [8, 256, 32, 32]    float32 
Dis_stg1.4.conv0  590080      16       [8, 256, 64, 64]    float32 
Dis_stg1.4.conv1  590080      16       [8, 256, 32, 32]    float32 
Dis_stg1.4        -           -        [8, 256, 32, 32]    float32 
Dis_stg1.5.skip   65536       16       [8, 256, 16, 16]    float32 
Dis_stg1.5.conv0  590080      16       [8, 256, 32, 32]    float32 
Dis_stg1.5.conv1  590080      16       [8, 256, 16, 16]    float32 
Dis_stg1.5        -           -        [8, 256, 16, 16]    float32 
Dis_stg1.6.skip   65536       16       [8, 256, 8, 8]      float32 
Dis_stg1.6.conv0  590080      16       [8, 256, 16, 16]    float32 
Dis_stg1.6.conv1  590080      16       [8, 256, 8, 8]      float32 
Dis_stg1.6        -           -        [8, 256, 8, 8]      float32 
Dis_stg1.7.skip   65536       16       [8, 256, 4, 4]      float32 
Dis_stg1.7.conv0  590080      16       [8, 256, 8, 8]      float32 
Dis_stg1.7.conv1  590080      16       [8, 256, 4, 4]      float32 
Dis_stg1.7        -           -        [8, 256, 4, 4]      float32 
Dis_stg1.8        -           -        [8, 257, 4, 4]      float32 
Dis_stg1.9        592384      16       [8, 256, 4, 4]      float32 
fc0_stg1          1048832     -        [8, 256]            float32 
fc1_stg1          257         -        [8, 1]              float32 
---               ---         ---      ---                 ---     
Total             36231618    736      -                   -       

Setting up augmentation...
Distributing across 2 GPUs...
Setting up training phases...
Exporting sample images...
Traceback (most recent call last):
  File "train.py", line 648, in <module>
    main() # pylint: disable=no-value-for-parameter
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/click/decorators.py", line 33, in new_func
    return f(get_current_context(), *args, **kwargs)
  File "train.py", line 643, in main
    torch.multiprocessing.spawn(fn=subprocess_fn, args=(args, temp_dir), nprocs=args.num_gpus)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/home/nnthao/project/FDA/train.py", line 471, in subprocess_fn
    training_loop.training_loop(rank=rank, **args)
  File "/home/nnthao/project/FDA/training/training_loop.py", line 326, in training_loop
    loss.accumulate_gradients(phase=phase.name, real_img=real_img, mask=mask, real_c=real_c, gen_z=gen_z, gen_c=gen_c, sync=sync, gain=gain)
  File "/home/nnthao/project/FDA/losses/loss.py", line 75, in accumulate_gradients
    gen_img, _gen_ws, gen_img_stg1 = self.run_G(real_img, mask, gen_z, gen_c, sync=(sync and not do_Gpl)) # May get synced by Gpl.
  File "/home/nnthao/project/FDA/losses/loss.py", line 51, in run_G
    img, img_stg1 = self.G_synthesis(img_in, mask_in, ws, return_stg1=True)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 705, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/nnthao/project/FDA/networks/mat.py", line 909, in forward
    out_stg1 = self.first_stage(images_in, masks_in, ws, noise_mode=noise_mode)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/nnthao/project/FDA/networks/mat.py", line 788, in forward
    self.yolov5.warmup(imgsz=(1 if self.yolov5.pt or self.yolov5.triton else batch_size, 3, *imgsz))  # warmup
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/yolov5/models/common.py", line 604, in warmup
    self.forward(im)  # warmup
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/yolov5/models/common.py", line 522, in forward
    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/yolov5/models/yolo.py", line 209, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/yolov5/models/yolo.py", line 121, in _forward_once
    x = m(x)  # run
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/yolov5/models/common.py", line 57, in forward
    return self.act(self.bn(self.conv(x)))
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/media/nnthao/miniconda3/envs/mat_inpainting/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 395, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Expected tensor for argument #1 'input' to have the same device as tensor for argument #2 'weight'; but device 0 does not equal 1 (while checking arguments for cudnn_convolution)

